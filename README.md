<p align=center><img src=https://d31uz8lwfmyn8g.cloudfront.net/Assets/logo-henry-white-lg.png><p>

# **Link de la aplicacion de consulta y recomendacion de peliculas:** **[API deploy](https://api-pi-danser.onrender.com/docs#/)** :sunglasses:

<h1 align=center> Proyecto Individual #1 Data Science - MLOps </h1>

<h2 align=center> En que consiste el proyecto :point_right:</h2>

A partir de 2 bases de datos no estructuradas de peliculas, se realizo el proceso ETL, se realizo un modelo de ML basado en contenido  para la recomendaci贸n de peliculas y se dispuso de todo este tratamiento en una API para se sea consumida por cualquier departamento de la compa帽ia.

<p align="center">
<img src="https://user-images.githubusercontent.com/67664604/217914153-1eb00e25-ac08-4dfa-aaf8-53c09038f082.png"  height=300>
</p>

<h1 align=center>Desarrollo del trabajo :construction_worker:</h1>

# - **Extracci贸n, transformacion y carga - ETL**

Cuento originalmente con 2 archivos csv y se encuentran en [Datasets](https://github.com/danser996/PI_DS/tree/master/Dataset).

* movies: que es donde esta toda la informacion de la pelicula como, titulo, overview, gasto, ingresos, tiempo de duracion, genero, compa帽ia que la desarrollo, paises donde fue grabada, idiomas a las que fue traducido, etc.
    
* credits: que cuenta con la informacion de todos los empleados que conformaron la pelicula yendo desde el directores y actores hasta productos musicales.

Mis datos cuentan con poca madurez(ok, es nula ): Datos anidados, sin transformar, no hay procesos automatizados para la actualizaci贸n de nuevas pel铆culas o series, entre otras cosas, haciendo mi trabajo imposible .

Se empezo desde cero, haciendo un trabajo de Data Engineer く, se inicia con el proceso ETL, consistiendo este en desanidar la informacion que esta contenida dentro de los diccionarios en algunos de los campos del dataset, se modelo a una base de datos relacional.

Todo el proceso ETL se encuentra en [proceso ETL de dataset movies](https://github.com/danser996/PI_DS/blob/master/code/etl_movies.ipynb) y [proceso ETL de dataset credits](https://github.com/danser996/PI_DS/blob/master/code/etl_credits.ipynb).

La combinacion de las 2 bases de datos se hizo por medio de id de las peliculas y el proceso se encuentra en [Combinacion data](https://github.com/danser996/PI_DS/blob/master/code/data_combination.ipynb).

La base de datos completamente tratada y limpia se encuentra en [Dataset_def](https://github.com/danser996/PI_DS/tree/master/Dataset_def) y el nombre es data_movies_full.zip

<p align=center><img src=https://tableauperu.com/wp-content/uploads/2021/10/que-es-etl-1024x1024.png><p>

## - **Analisis exploratorio de datos - EDA** 

El an谩lisis exploratorio de datos (EDA, por sus siglas en ingl茅s, Exploratory Data Analysis) es una etapa fundamental en el proceso de an谩lisis de datos. Consiste en investigar y examinar un conjunto de datos para comprender su estructura, identificar patrones, descubrir relaciones entre variables y detectar posibles inconsistencias o anomal铆as.

El objetivo principal del an谩lisis exploratorio de datos es obtener informaci贸n y conocimientos preliminares sobre los datos antes de aplicar t茅cnicas m谩s avanzadas de modelado o inferencia estad铆stica. Proporciona una visi贸n general de los datos y ayuda a formular preguntas de investigaci贸n, validar suposiciones y generar hip贸tesis.

![WC](/src/WORDCLOUD.png)

    - Imagen generada a partir de las palabras mas recurrentes en el nombre de las peliculas del dataset

Todo el analisis de este proyecto lo pueden encontrar en el notebook [EDA](https://github.com/danser996/PI_DS/blob/master/code/EDA.ipynb).

## - **Sistema de recomendacion de peliculas** :wink:
## Tratamiento de campos usados para el modelo ML

Para el sistema de recomendacion de peliculas tome del dataset limpio los campos title(titulo de la pelicula), name_actor(nombre de los actores de la pelicula) y overview(descripcion general de la pelicula), tome todos los actores de cada pelicula y los uni a una lista, cada pelicula contaba con los campos titulo, overview y lista de actores que la conforman,las lista de actores se unieron para que quedaron todos en un solo string asi: 
```python
actors = ['Jim Varney', 'John Ratzenberger', 'Wallace Shawn']
' '.join(actors)
'Jim Varney John Ratzenberger Wallace Shawn'
```
Finalmente se concateno los campos title, overview y name_actor y se guardo en un nuevo campo (tags), cada pelicula cuenta con un campo llamado tags, en 茅l esta escrito el nombre de la pelicula, el overview y los actores que en ella trabajan quedando por ejemplo de la siguiente manera:

```python
campo_concat 
"toy story tom hanks tim allen don rickles jim varney wallace shawn john ratzenberger annie potts john morris erik von detten laurie metcalf r. lee ermey sarah freeman penn jillette animation comedy family led by woody, andy's toys live happily in his room until andy's birthday brings buzz lightyear onto the scene. afraid of losing his place in andy's heart, woody plots against buzz. but when circumstances separate buzz and woody from their owner, the duo eventually learns to put aside their differences."
```

## **Modelo machine learning**

## NLP (Natural Language Processing)

Es un campo de estudio dentro de la inteligencia artificial y la ling眉铆stica computacional que se centra en la interacci贸n entre las computadoras y el lenguaje humano. El objetivo principal del NLP es permitir que las m谩quinas comprendan, interpreten y generen el lenguaje humano de manera natural.

Preprocesamiento de texto: Aplica t茅cnicas de preprocesamiento de texto para convertir el texto en un formato adecuado para el an谩lisis. Esto puede incluir tokenizaci贸n (dividir el texto en unidades m谩s peque帽as, como palabras o frases), eliminaci贸n de stopwords (palabras comunes sin valor informativo) y normalizaci贸n de palabras (por ejemplo, convertir palabras en su forma base, como "corriendo" a "correr").

## Algoritmo utilizado: Similaridad del coseno

La similaridadd del coseno es una medida utilizada en el procesamiento del lenguaje natural y en la recuperaci贸n de informaci贸n para determinar la similitud entre dos vectores de caracter铆sticas. Se calcula utilizando el coseno del 谩ngulo entre los vectores en un espacio vectorial.

El resultado de la similaridad del coseno es un valor entre -1 y 1. Un valor de 1 indica una similitud perfecta entre los vectores, mientras que un valor de -1 indica una similitud completamente opuesta. Un valor cercano a 0 indica poca similitud entre los vectores.

![Similaridad coseno](/src/SIM_COSINE.png)

## Scikit-Learn
Se utilizo el modulo Scikit-learn y la clase TfidfVectorizer de sklearn para calcular la frecuencia de las palabras que aparecen en el campo tags y se ignoraron todas las palabras comunes del ingles(stopwords) ya que no aportar valor a mi modelamiento.

<!-- ![Sklearn modulo](/src/skl.png) -->
<p align=center><img src=https://upload.wikimedia.org/wikipedia/commons/0/05/Scikit_learn_logo_small.svg><p>

```python
tfidf = TfidfVectorizer(stop_words='english')
df['tags'].fillna('', inplace=True) # reemplazamos los valores nulos del dataframe por un vacio
tfidf_matrix = tfidf.fit_transform(df['tags']) # creamos la matriz donde estaran las palabras de cada tag y su frecuencia
```

Se creo una funcion que recibe el titulo de una pelicula y busca entre todo el dataset las que 5 que tengan mas palabras relacionadas de acuerdo al campo tags y las ordena mayor a menor similitud y las retorna.

```python
rec = recomendacion('Toy Story')
#  La respuesta de la funcion es:
La pelicula que viste es: Toy Story
Tu recomendacion es: 
1 - Toy Story 2
2 - Rebel Without A Cause
3 - The Thin Red Line
4 - Radio Days
5 - The Sunchaser
```

Nota: El dataset completo es de 45000 peliculas, para la implementacion del algoritmo solo se usa un muestro de 3000 ya que los recursos de maquina son limitados, por ende solo recomendara peliculas que esten dentro de esta muestra.

Si se cuenta con recursos de maquina superiores la recomendacion es mas acertada. 

Todo este proceso se encuentra en [Modelo ML](https://github.com/danser996/PI_DS/blob/master/code/MODEL_SIST_REC.ipynb)

## **Desarrollo API**
## API
API es el acr贸nimo de "Application Programming Interface" (Interfaz de Programaci贸n de Aplicaciones). Se trata de un conjunto de reglas y protocolos que permite a diferentes aplicaciones y sistemas comunicarse e interactuar entre s铆 de manera estandarizada.

Una API define las funciones y m茅todos que una aplicaci贸n proporciona para que otros programas puedan utilizar sus servicios y acceder a sus datos de manera controlada. Funciona como una capa de abstracci贸n que permite a los desarrolladores utilizar ciertas funcionalidades de una aplicaci贸n o servicio sin necesidad de conocer todos los detalles internos de su implementaci贸n.

<!-- ![API](/src/appmaster.avif) -->
<p align=center><img src=https://appmaster.io/cdn-cgi/image/width=768,quality=83,format=auto/api/_files/PqV7MuNwv89GrZvBd4LNNK/download/><p>

## FastAPI
Para desarrollar la API, se opt贸 por utilizar FastAPI, un framework r谩pido y eficiente en Python. Se hizo uso del potencial del DataFrame de Python para manipular y analizar los datos necesarios.

Toda el desarrollo de la API se encuentra en el [Repositorio de la API](https://github.com/danser996/PI_DS_deploy).

![FastAPI](/src/FA.png)

## Render
Una vez completada la implementaci贸n y las pruebas, la API fue desplegada en la plataforma Render, que ofrece una infraestructura escalable y confiable para alojar aplicaciones web. Esta combinaci贸n de tecnolog铆as permiti贸 crear una API robusta y de alto rendimiento, capaz de procesar solicitudes y brindar respuestas eficientes a los usuarios. El despliegue en Render garantiz贸 una disponibilidad constante y una buena experiencia de uso.

 ![Render](/src/RENDER.png)

